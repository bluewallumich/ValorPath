{
  "cells": [
    {
      "cell_type": "code",
      "id": "QJNqepz9wj9qGWtMqeUPI9gx",
      "metadata": {
        "tags": [],
        "id": "QJNqepz9wj9qGWtMqeUPI9gx"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpeKcQcw5E5T",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732642017994,
          "user_tz": 300,
          "elapsed": 8290,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22f691d1-41cd-49cb-9b3d-b4e105061a28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install -q --upgrade tensorflow keras keras-nlp transformers torch tqdm"
      ],
      "id": "SpeKcQcw5E5T"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade kaggle kagglehub -q"
      ],
      "metadata": {
        "id": "BhVekTWRUfHZ"
      },
      "id": "BhVekTWRUfHZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "kagglehub.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "45499828171143beb531ea7b242eb349",
            "08b3b1eaa0214741963b63bfb599ba19",
            "b2ef4828edfa4384a3839fd5615c8ead",
            "c1e481170cc247298fdb9afce067bc06",
            "024362481ac64922af5f5402e0c1b1a8",
            "d1928f54592b4987a64f3430fc584e84",
            "261d44ba80a441f7bc0208a33cadbc18",
            "763622d911184d9da1cbfe389e1541ea",
            "46225596a1574405b45aac608b28bde9",
            "74eb573d6c9b445ba0c71b92e5fe99fa",
            "73e8b7676b804d86ace2426b4090f211",
            "5f72206ac19a4104b52b03186c3299e5",
            "7e34d864fbf648cfa7656c683ff4b592",
            "f86d0b12ba0043da8a239b239b82bbe7",
            "6a799611994e46368831b3dd332001d5",
            "d859b7fdcf8e4025a64128be1a53acad",
            "4e24a9ba3c1243a9a92b20da81ab41c0",
            "46f24f06caf54bfaaedade51484d379c",
            "9d76e4b99e07459981390e494181d0a0",
            "f764de52d5074cbc8921474e20196185",
            "df7acd76e1f14bbda45f9ed524dc1369",
            "9e44e362df21436190530c0fd5c74988",
            "4f5503a771dc4d87b561fa42ffff13be"
          ]
        },
        "id": "sWk_OKZT6lkv",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732642025065,
          "user_tz": 300,
          "elapsed": 366,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "7b0b521e-be4b-449b-fb98-d73a23924232"
      },
      "id": "sWk_OKZT6lkv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45499828171143beb531ea7b242eb349"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle credentials set.\n",
            "Kaggle credentials successfully validated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rtOCAOps627D"
      },
      "id": "rtOCAOps627D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemma_lm = GemmaCausalLM.from_preset(\"gemma_2b_en\")"
      ],
      "metadata": {
        "id": "Kvsu4mzXe_RH"
      },
      "id": "Kvsu4mzXe_RH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model name\n",
        "MODEL_NAME = \"gemma_2b_en\"\n",
        "\n",
        "# Initialize GemmaCausalLM with the preset\n",
        "gemma_lm = GemmaCausalLM.from_preset(MODEL_NAME)\n",
        "\n",
        "# Enable LoRA with rank=64\n",
        "gemma_lm.backbone.enable_lora(rank=64)\n",
        "\n",
        "# Set float precision to bfloat16\n",
        "keras.backend.set_floatx(\"bfloat16\")\n",
        "\n",
        "print(f\"Model '{MODEL_NAME}' initialized with LoRA and bfloat16 precision.\")"
      ],
      "metadata": {
        "id": "wRS_iDsrJjzO",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732642188027,
          "user_tz": 300,
          "elapsed": 32545,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82257318-f30f-41da-a8e1-6d2a64bd36f8"
      },
      "id": "wRS_iDsrJjzO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 'gemma_2b_en' initialized with LoRA and bfloat16 precision.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gemma_lm.summary()"
      ],
      "metadata": {
        "id": "LWvN_fJR7aFS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732642206603,
          "user_tz": 300,
          "elapsed": 185,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "a153ddbb-cebc-4615-bcc0-d0afc0e88538"
      },
      "id": "LWvN_fJR7aFS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
              "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
              "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,527,995,904\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,527,995,904</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,527,995,904\u001b[0m (9.42 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,527,995,904</span> (9.42 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,823,488\u001b[0m (83.25 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,823,488</span> (83.25 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_URL = \"https://huggingface.co/datasets/vetHealthGuy/Veteran_Affairs_NorthEast_Region_Conversational_Dataset/resolve/main/Updated_VA_Facilities_Conversational_with_Phone.csv\"\n",
        "\n",
        "!wget -nv -nc -O vet_chat.csv $DATASET_URL"
      ],
      "metadata": {
        "id": "9-V55Hry8h7a"
      },
      "id": "9-V55Hry8h7a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Path\n",
        "NEW_DATASET_PATH = \"vet_chat.csv\"\n",
        "PROMPT_TEMPLATE = \"{Prompt} {Response}\"\n",
        "\n",
        "# Generate training data from CSV\n",
        "def generate_training_data(training_ratio: int = 100) -> list[str]:\n",
        "    \"\"\"\n",
        "    Generate formatted training data from a CSV file.\n",
        "\n",
        "    Args:\n",
        "    - training_ratio (int): Percentage of the dataset to use for training (1-100).\n",
        "\n",
        "    Returns:\n",
        "    - list[str]: List of formatted training examples.\n",
        "    \"\"\"\n",
        "    assert 0 < training_ratio <= 100\n",
        "    data = []\n",
        "    with open(NEW_DATASET_PATH, newline='') as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        for row in reader:\n",
        "            if row.get(\"context\"):\n",
        "                continue\n",
        "            data.append(PROMPT_TEMPLATE.format(Prompt=row['Prompt'], Response=row['Response']))\n",
        "    total_data_count = len(data)\n",
        "    training_data_count = total_data_count * training_ratio // 100\n",
        "    print(f\"Training examples: {training_data_count}/{total_data_count}\")\n",
        "    return data[:training_data_count]\n",
        "\n",
        "# Generate training data\n",
        "training_data = generate_training_data(training_ratio=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1YyXvvGLSs3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732642273964,
          "user_tz": 300,
          "elapsed": 130,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "78c966d9-5693-4307-9d4a-723be5bf1c62"
      },
      "id": "P1YyXvvGLSs3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training examples: 329/3290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def finetune_gemma(model: GemmaCausalLM, data: list[str]):\n",
        "    \"\"\"\n",
        "    Fine-tune the GemmaCausalLM model.\n",
        "\n",
        "    Args:\n",
        "    - model: GemmaCausalLM model to fine-tune.\n",
        "    - data: List of training examples as strings.\n",
        "    \"\"\"\n",
        "    # Reduce the input sequence length to limit memory usage\n",
        "    model.preprocessor.sequence_length = 64\n",
        "\n",
        "    # Define early stopping\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='loss',\n",
        "        patience=2,  # Allow 2 epochs of no improvement before stopping\n",
        "        restore_best_weights=True  # Restore the best model weights\n",
        "    )\n",
        "\n",
        "    # Configure the AdamW optimizer\n",
        "    optimizer = keras.optimizers.AdamW(\n",
        "        learning_rate=5e-6,\n",
        "        weight_decay=0.01,\n",
        "    )\n",
        "\n",
        "    # Convert data to a tf.data.Dataset and batch it\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(data).batch(4)\n",
        "\n",
        "    # Compile the model with greedy decoding for text generation\n",
        "    model.compile(\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer=optimizer,\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "        sampler=\"greedy\"  # Greedy decoding for text generation\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(dataset, epochs=4, callbacks=[early_stopping])\n",
        "\n",
        "print(\"Fine-tuning function ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0HWuCJqHCd_",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732642299808,
          "user_tz": 300,
          "elapsed": 157,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "b0fb69fc-7437-47d4-c607-a843abe1430b"
      },
      "id": "w0HWuCJqHCd_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning function ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the model using the finetune_gemma function\n",
        "finetune_gemma(gemma_lm, training_data)\n",
        "\n",
        "print(\"Fine-tuning complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYlncIrHISwe",
        "outputId": "45f0f66b-5aae-470e-d0d0-b587af65f80a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732646367077,
          "user_tz": 300,
          "elapsed": 4046234,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "oYlncIrHISwe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1046s\u001b[0m 12s/step - loss: 17.7128 - sparse_categorical_accuracy: 0.5462 - weighted_sparse_categorical_accuracy: 0.5719\n",
            "Epoch 2/4\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m981s\u001b[0m 12s/step - loss: 16.1674 - sparse_categorical_accuracy: 0.5331 - weighted_sparse_categorical_accuracy: 0.5582\n",
            "Epoch 3/4\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m972s\u001b[0m 12s/step - loss: 13.2783 - sparse_categorical_accuracy: 0.5259 - weighted_sparse_categorical_accuracy: 0.5505\n",
            "Epoch 4/4\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1031s\u001b[0m 12s/step - loss: 9.8348 - sparse_categorical_accuracy: 0.4350 - weighted_sparse_categorical_accuracy: 0.4555\n",
            "Fine-tuning complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test prompts\n",
        "TEST_PROMPTS = [\n",
        "    \"Where are services near Philadelphia?\",\n",
        "    \"How can I apply for healthcare benefits as a veteran in Reading, Pa?\",\n",
        "    \"Are there VA mental health resources at the Virginia\",\n",
        "    \"Where is the nearest VA hospital in New York Queens borough?\",\n",
        "    \"What is the phone number for the VA in Boston?\"\n",
        "]"
      ],
      "metadata": {
        "id": "hyaygb_XPfj1"
      },
      "id": "hyaygb_XPfj1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the fine-tuned model\n",
        "for prompt in TEST_PROMPTS:\n",
        "    # Generate a response\n",
        "    response = gemma_lm.generate(prompt, max_length=40)  # Adjust max_length as needed\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Response: {response}\\n{'-' * 40}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6Fqw033xpyY",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732646624928,
          "user_tz": 300,
          "elapsed": 46450,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "abb9f080-08bf-4045-b73a-4b1cafef6110"
      },
      "id": "N6Fqw033xpyY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Where are services near Philadelphia?\n",
            "Response: Where are services near Philadelphia?\n",
            "\n",
            "The following is a list of services that are available to you.\n",
            "\n",
            "* <strong>Online</strong>: You can access your account and make payments online.\n",
            "*\n",
            "----------------------------------------\n",
            "Prompt: How can I apply for healthcare benefits as a veteran in Reading, Pa?\n",
            "Response: How can I apply for healthcare benefits as a veteran in Reading, Pa?\n",
            "\n",
            "Answer:\n",
            "\n",
            "Step 1/5\n",
            "1. First, you need to determine if you are eligible for healthcare\n",
            "----------------------------------------\n",
            "Prompt: Are there VA mental health resources at the Virginia\n",
            "Response: Are there VA mental health resources at the Virginia Tech Carilion School of Medicine?\n",
            "\n",
            "Yes, the VA has a number of resources for medical students and residents.\n",
            "\n",
            "* The VA has a number\n",
            "----------------------------------------\n",
            "Prompt: Where is the nearest VA hospital in New York Queens borough?\n",
            "Response: Where is the nearest VA hospital in New York Queens borough?\n",
            "\n",
            "Answer:\n",
            "\n",
            "Step 1/3\n",
            "1. First, we need to find the VA hospital in the United States.\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "Prompt: What is the phone number for the VA in Boston?\n",
            "Response: What is the phone number for the VA in Boston?\n",
            "\n",
            "I have a question about the 2019-2020 school year. I am a student at a community college\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion on Model Responses\n",
        "The fine-tuned GemmaCausalLM model demonstrates some promising capabilities but falls short in providing accurate and contextually appropriate responses to the prompts. The following observations were made:\n",
        "\n",
        "## Repetition of the Prompt:\n",
        "\n",
        "The model frequently echoes the prompt in its response rather than generating meaningful content.\n",
        "Example: For the prompt \"Where are services near Philadelphia?\", the response began by repeating the question verbatim.\n",
        "Incomplete or Generic Responses:\n",
        "\n",
        "The model provides incomplete answers that lack specific details or actionable information.\n",
        "Example: For \"How can I apply for healthcare benefits as a veteran in Reading, Pa?\", the response starts with \"Step 1/5\" but does not proceed to provide further steps.\n",
        "## Irrelevant Content:\n",
        "\n",
        "Some responses include irrelevant or unrelated content, such as references to educational contexts or generic lists.\n",
        "Example: For \"What is the phone number for the VA in Boston?\", the response unexpectedly shifted to mentioning the 2019-2020 school year and community college.\n",
        "## Missed Opportunities for Specificity:\n",
        "\n",
        "The model fails to leverage the fine-tuning data to provide specific answers, such as accurate phone numbers or locations.\n",
        "Future Recommendations\n",
        "While the current performance of the model is not fully aligned with expectations, it establishes a solid foundation for future development.\n",
        "## To improve the model:\n",
        "\n",
        "### Enhance the Training Dataset:\n",
        "Include more diverse and detailed examples with well-defined prompts and accurate, complete responses.\n",
        "### Increase Fine-Tuning Epochs:\n",
        "Allow the model more time to learn from the fine-tuning dataset by increasing the number of epochs while monitoring for overfitting.\n",
        "### Adjust Hyperparameters:\n",
        "Experiment with learning rates, sequence lengths, and batch sizes to optimize performance.\n",
        "### Incorporate Domain-Specific Tokenizers:\n",
        "If needed, include a domain-specific tokenizer to better handle specialized language and context.\n",
        "## Conclusion\n",
        "While the model did not meet the requirements for this project, it showcases potential for generating structured responses and provides a good starting point for future enhancements. With further refinement and targeted adjustments, the model could become a valuable tool for answering veteran-focused queries effectively."
      ],
      "metadata": {
        "id": "BaLJCCBtzyIg"
      },
      "id": "BaLJCCBtzyIg"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-storage -q"
      ],
      "metadata": {
        "id": "M52oJadY00Ft"
      },
      "id": "M52oJadY00Ft",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud config get core/account"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7fG_dwy06c1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732647632433,
          "user_tz": 300,
          "elapsed": 2079,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "d58e63d1-81ec-448e-f661-4e13cc0d2365"
      },
      "id": "y7fG_dwy06c1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "awdatascience@gmail.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate the Cloud SDK with your credentials\n",
        "# !gcloud auth login\n",
        "\n",
        "# Authenticate code and libraries with your credentials\n",
        "# !gcloud auth application-default login"
      ],
      "metadata": {
        "id": "7f-q8NWq0_Qr"
      },
      "id": "7f-q8NWq0_Qr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = !gcloud config get core/project\n",
        "PROJECT_ID = res[0]\n",
        "\n",
        "print(f\"{PROJECT_ID=}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFAdAfU-2NhS",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732647648966,
          "user_tz": 300,
          "elapsed": 1030,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "74f5c517-49bc-4487-ed02-13a85b6a1d9f"
      },
      "id": "FFAdAfU-2NhS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROJECT_ID='velvety-study-440800-e0'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List your projects\n",
        "# !gcloud projects list\n",
        "\n",
        "# Define the default project\n",
        "# PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "# !gcloud config set core/project $PROJECT_ID"
      ],
      "metadata": {
        "id": "ZkQl5A4i2PmC"
      },
      "id": "ZkQl5A4i2PmC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "REGION = \"us-central1\"  # @param {type: \"string\"}\n",
        "\n",
        "!gcloud config set ai/region $REGION"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyFrlhZ-2Rnq",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732647678588,
          "user_tz": 300,
          "elapsed": 1262,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "64d8bc5c-5f75-472d-b3ee-7eeb28665c02"
      },
      "id": "cyFrlhZ-2Rnq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [ai/region].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a bucket related to your project\n",
        "BUCKET_URI = f\"gs://gemma-{PROJECT_ID}-unique\"\n",
        "# Or use an existing one\n",
        "# BUCKET_URI = \"gs://\"  # @param {type:\"string\"}\n",
        "\n",
        "res = !gcloud storage buckets describe $BUCKET_URI --format \"value(name)\"\n",
        "if len(res) == 1 and \"ERROR\" not in res[0]:\n",
        "    print(\"✔️ The bucket exists\")\n",
        "else:\n",
        "    print(\"⚙️ Creating the bucket…\")\n",
        "    !gcloud storage buckets create $BUCKET_URI --project $PROJECT_ID --location $REGION"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Onw-qzl22WxD",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732647692444,
          "user_tz": 300,
          "elapsed": 3868,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "75413a81-4f94-4b3f-f5d3-407f4554a3b9"
      },
      "id": "Onw-qzl22WxD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚙️ Creating the bucket…\n",
            "Creating gs://gemma-velvety-study-440800-e0-unique/...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUCKET_URI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "J3dSQU1h3ux-",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732648045830,
          "user_tz": 300,
          "elapsed": 157,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "46ea39e7-c42c-4ded-8e5d-8383352f3c73"
      },
      "id": "J3dSQU1h3ux-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gs://gemma-velvety-study-440800-e0-unique'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUCKET_PATH = f\"{BUCKET_URI}/models\""
      ],
      "metadata": {
        "id": "6iJ7n4Sg2Zgq"
      },
      "id": "6iJ7n4Sg2Zgq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Keras model locally\n",
        "gemma_lm.save(\"fine_tuned_gemma_model.keras\")"
      ],
      "metadata": {
        "id": "-fhwZxDF3JMK"
      },
      "id": "-fhwZxDF3JMK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud storage rsync --recursive --verbosity error $HUGGINGFACE_MODEL_DIR $DEPLOYED_MODEL_URI"
      ],
      "metadata": {
        "id": "yg4u9AbBY9IF"
      },
      "id": "yg4u9AbBY9IF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model in H5 format locally\n",
        "gemma_lm.save(\"fine_tuned_gemma_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmLO3SNO4LCQ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732648322481,
          "user_tz": 300,
          "elapsed": 88805,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "3661aa0c-eb82-4984-8c66-99a436bdb52c"
      },
      "id": "KmLO3SNO4LCQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GemmaConfig, AutoModelForCausalLM\n",
        "\n",
        "# Define Hugging Face Model Configuration\n",
        "hf_config = GemmaConfig(\n",
        "    vocab_size=30522,             # Match the vocabulary size of your model\n",
        "    n_layer=12,                   # Number of transformer layers\n",
        "    n_head=12,                    # Number of attention heads\n",
        "    hidden_size=768,              # Hidden dimension size\n",
        "    intermediate_size=3072,       # Feedforward layer dimension\n",
        "    max_position_embeddings=512   # Max sequence length\n",
        ")\n",
        "\n",
        "# Directory to save the Hugging Face model\n",
        "hf_model_dir = \"huggingface_model\"\n",
        "os.makedirs(hf_model_dir, exist_ok=True)\n",
        "\n",
        "# Save Hugging Face model\n",
        "torch_model = AutoModelForCausalLM.from_config(hf_config)\n",
        "torch_model.save_pretrained(hf_model_dir)\n",
        "\n",
        "print(f\"Model saved in Hugging Face format in directory '{hf_model_dir}'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjhnwdMT4el5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732648609291,
          "user_tz": 300,
          "elapsed": 28478,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "20c777ad-aa5a-4dd7-8d44-4ac519afafa5"
      },
      "id": "BjhnwdMT4el5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
            "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
            "`config.hidden_activation` if you want to override this behaviour.\n",
            "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved in Hugging Face format in directory 'huggingface_model'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_DIRS=[\"/content/keras_model\", \"/content/H5_Weights\"]\n",
        "DEPLOYED_MODEL_URI=\"gs://gemma-velvety-study-440800-e0-unique\"\n",
        "\n",
        "for model_dir in MODEL_DIRS:\n",
        "    !gcloud storage rsync --recursive --verbosity error $model_dir $DEPLOYED_MODEL_URI\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOHlHw5FVryz",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732657946334,
          "user_tz": 300,
          "elapsed": 684516,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "e2eb6881-d156-418b-eac0-18ca035fd646"
      },
      "id": "IOHlHw5FVryz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At file:///content/keras_model/**, worker process 71930 thread 131927862427648 listed 1...\n",
            "At gs://gemma-velvety-study-440800-e0-unique/**, worker process 71930 thread 131927862427648 listed 6...\n",
            "Copying file:///content/keras_model/fine_tuned_gemma_model.keras to gs://gemma-velvety-study-440800-e0-unique/fine_tuned_gemma_model.keras\n",
            "\n",
            "Average throughput: 26.7MiB/s\n",
            "At file:///content/H5_Weights/**, worker process 73229 thread 133674141175808 listed 1...\n",
            "At gs://gemma-velvety-study-440800-e0-unique/**, worker process 73229 thread 133674141175808 listed 7...\n",
            "Copying file:///content/H5_Weights/fine_tuned_gemma_model.h5 to gs://gemma-velvety-study-440800-e0-unique/fine_tuned_gemma_model.h5\n",
            "\n",
            "Average throughput: 40.5MiB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the models.\n"
      ],
      "metadata": {
        "id": "pA1Xf0T2_l8b"
      },
      "id": "pA1Xf0T2_l8b"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "\n",
        "# Load the model from the .keras file\n",
        "model = load_model(\"fine_tuned_gemma_model.keras\", compile=False)\n",
        "\n",
        "# Recompile the model (optional, depending on your use case)\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",  # Match the loss used during training\n",
        "    optimizer=AdamW(learning_rate=5e-6),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "print(\"Model loaded and recompiled successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wCiAfXX48cm",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732649761540,
          "user_tz": 300,
          "elapsed": 171180,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "36d923fa-56fe-4297-f364-c3817da88c40"
      },
      "id": "9wCiAfXX48cm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 146 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded and recompiled successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "h-8cRIycBbFO",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732650583920,
          "user_tz": 300,
          "elapsed": 184,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "dc2ec310-3a33-45c4-b006-47eabb23ebae"
      },
      "id": "h-8cRIycBbFO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
              "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
              "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from keras_nlp.models import GemmaCausalLM\n",
        "\n",
        "# Load the model with the custom class\n",
        "gemma_lm.load_weights(\"fine_tuned_gemma_model.h5\")\n",
        "\n",
        "print(\"Model loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFgbKsjM8SIk",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732650460339,
          "user_tz": 300,
          "elapsed": 143475,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "aae93bfd-001a-4d22-e4ca-5633ba68944d"
      },
      "id": "qFgbKsjM8SIk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gemma_lm.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "XdMBUoVg8cgd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732650571811,
          "user_tz": 300,
          "elapsed": 204,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "8f3cdcd2-fdc1-4dfb-c7f4-89827b6bfccf"
      },
      "id": "XdMBUoVg8cgd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
              "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
              "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,527,995,904\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,527,995,904</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,571,642,882\u001b[0m (9.58 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,571,642,882</span> (9.58 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,823,488\u001b[0m (83.25 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,823,488</span> (83.25 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m43,646,978\u001b[0m (166.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,646,978</span> (166.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "# Load the Hugging Face model  ##No tokenizer was used\n",
        "model_dir = \"/content/huggingface_model\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_dir)\n",
        "\n",
        "print(\"Model loaded successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euPY-aQr6h02",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732650962870,
          "user_tz": 300,
          "elapsed": 335,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "127f076e-80a2-4454-c233-1ec98de25e5a"
      },
      "id": "euPY-aQr6h02",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Example input prompt (you need to convert text to token IDs based on your model's vocabulary)\n",
        "prompt = \"What services are available for veterans at the VA in Philadelphia?\"\n",
        "\n",
        "# Dummy input IDs (replace with actual token IDs if available)\n",
        "# For example, [101] could represent a start token, and [102] an end token\n",
        "input_ids = torch.tensor([[101, 2023, 2003, 1037, 5204, 102]])\n",
        "\n",
        "# Generate output\n",
        "outputs = model.generate(input_ids=input_ids, max_length=50)\n",
        "\n",
        "print(\"Generated Response (token IDs):\", outputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHfYBsyQBq2e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732651030450,
          "user_tz": 300,
          "elapsed": 34263,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "9ddd2aea-82dd-4833-ebf7-065bdb25f7ad"
      },
      "id": "uHfYBsyQBq2e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Response (token IDs): tensor([[  101,  2023,  2003,  1037,  5204,   102, 24132, 24132, 24132, 24132,\n",
            "         24132, 24132, 24132, 24132, 24132, 24132, 24132, 24132, 24132, 24132,\n",
            "         24132, 24132, 24132, 24132, 24132, 24132, 24132, 24132, 24132, 24132,\n",
            "         24132, 24132, 24132, 24132, 24132, 24132, 24132, 24132, 24132, 24132,\n",
            "         24132, 24132, 24132, 24132, 24132, 24132, 24132, 24132, 24132, 24132]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example vocabulary with placeholder for unknown tokens\n",
        "vocab = {\n",
        "    101: \"[START]\",\n",
        "    2023: \"What\",\n",
        "    2003: \"services\",\n",
        "    1037: \"are\",\n",
        "    5204: \"available\",\n",
        "    102: \"[END]\",\n",
        "}\n",
        "\n",
        "# Decode the output token IDs\n",
        "decoded_response = \" \".join([vocab.get(token.item(), \"[UNK]\") for token in outputs[0]])\n",
        "print(\"Generated Response (decoded):\", decoded_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75VXcJ9NDBB1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732651231286,
          "user_tz": 300,
          "elapsed": 145,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "7bcd08de-2d37-445c-d9a3-30e45f472631"
      },
      "id": "75VXcJ9NDBB1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Response (decoded): [START] What services are available [END] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What Happened"
      ],
      "metadata": {
        "id": "OoiyjlXoFh_W"
      },
      "id": "OoiyjlXoFh_W"
    },
    {
      "cell_type": "markdown",
      "source": [
        "I didn' save a tokenizer or vocab.text  Since I do not have that much compute space or funding we will need to create something out of the dataset."
      ],
      "metadata": {
        "id": "ikVqsaH_Fluc"
      },
      "id": "ikVqsaH_Fluc"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece -q"
      ],
      "metadata": {
        "id": "OdQeAwpPS3PW"
      },
      "id": "OdQeAwpPS3PW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tempfile\n",
        "import sentencepiece as spm\n",
        "\n",
        "# Load the dataset\n",
        "dataset_path = \"vet_chat.csv\"\n",
        "data = pd.read_csv(dataset_path)\n",
        "\n",
        "# Filter out rows with empty prompts or responses\n",
        "data = data.dropna(subset=[\"Prompt\", \"Response\"])\n",
        "\n",
        "# Combine 'Prompt' and 'Response' as separate sentences, joined by newline\n",
        "combined_text = \"\\n\".join(data['Prompt'].astype(str) + \" \" + data['Response'].astype(str))\n",
        "print(f\"Combined text length: {len(combined_text)}\")\n",
        "\n",
        "# Write combined_text to a temporary file with proper sentence separation\n",
        "with tempfile.NamedTemporaryFile(delete=False, mode=\"w\", suffix=\".txt\") as temp_file:\n",
        "    temp_file.write(combined_text)\n",
        "    temp_file_path = temp_file.name\n",
        "\n",
        "# Validate the temporary file contents\n",
        "with open(temp_file_path, \"r\") as f:\n",
        "    file_contents = f.read()\n",
        "    print(f\"Sample file contents:\\n{file_contents[:500]}\")  # Display first 500 characters for verification\n",
        "\n",
        "# Train the SentencePiece model using a smaller vocab_size (<= 2549)\n",
        "spm.SentencePieceTrainer.train(input=temp_file_path, model_prefix=\"spm_model\", vocab_size=2500)\n",
        "\n",
        "# Load the trained SentencePiece model\n",
        "sp = spm.SentencePieceProcessor(model_file=\"spm_model.model\")\n",
        "\n",
        "# Display the vocabulary size\n",
        "vocab_size = sp.get_piece_size()\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw3Ba8uZDMq9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732654322068,
          "user_tz": 300,
          "elapsed": 668,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "15aa1cf7-a31c-4d4a-de93-7267ebb86881"
      },
      "id": "Zw3Ba8uZDMq9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined text length: 651285\n",
            "Sample file contents:\n",
            "Where is the VA facility in Danbury, CT? The VA facility in Danbury, CT is located at 7 Germantown Road, Ste 2B   Danbury, CT 06810. You can contact them at 203-798-8422  .\n",
            "Where is the VA facility in Danbury, CT? The VA facility in Danbury, CT is located at 131 West Street, Suite 2A, Second Floor   Danbury, CT 06810. You can contact them at 203-790-4000  .\n",
            "Where is the VA facility in Rocky Hill, CT? The VA facility in Rocky Hill, CT is located at 25 Elm Street, Suite A   Rocky Hill, CT 06067. Y\n",
            "Vocabulary size: 2500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test encoding with the trained tokenizer\n",
        "sample_prompt = \"Where is the VA facility in Danbury CT?\"\n",
        "encoded = sp.encode(sample_prompt, out_type=int)  # Get token IDs\n",
        "decoded = sp.decode(encoded)  # Convert token IDs back to text\n",
        "\n",
        "print(\"Encoded token IDs:\", encoded)\n",
        "print(\"Decoded text:\", decoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAO1vYO0Had4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732654587500,
          "user_tz": 300,
          "elapsed": 182,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "688bb552-960f-491a-b5cb-20fd757b9050"
      },
      "id": "NAO1vYO0Had4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded token IDs: [26, 10, 43, 3, 17, 5, 8, 14, 11, 12, 13, 6, 456, 118, 19]\n",
            "Decoded text: Where is the VA facility in Danbury CT?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vocabulary size:\", sp.get_piece_size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu45r37EUrpy",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732655630033,
          "user_tz": 300,
          "elapsed": 187,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "eb4c83e6-1fcd-42a1-eebe-790093034a85"
      },
      "id": "hu45r37EUrpy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 2500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate outputs\n",
        "outputs = model.generate(input_tensor, max_length=50)\n",
        "\n",
        "# Validate token IDs against SentencePiece vocabulary size\n",
        "vocab_size = sp.get_piece_size()\n",
        "output_ids = outputs[0].tolist()\n",
        "\n",
        "if any(token_id >= vocab_size or token_id < 0 for token_id in output_ids):\n",
        "    print(\"Generated token IDs exceed the tokenizer's vocabulary size.\")\n",
        "else:\n",
        "    print(\"Generated token IDs are within the tokenizer's vocabulary size.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnlxgmEQUus1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732655648187,
          "user_tz": 300,
          "elapsed": 5919,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "a38cbdba-d453-4e6b-fe54-e6a280d25091"
      },
      "id": "GnlxgmEQUus1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token IDs exceed the tokenizer's vocabulary size.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_decode_with_sentencepiece(ids, sp):\n",
        "    # Replace out-of-range IDs with the [UNK] token\n",
        "    vocab_size = sp.get_piece_size()\n",
        "    safe_ids = [token_id if 0 <= token_id < vocab_size else sp.unk_id() for token_id in ids]\n",
        "    return sp.decode(safe_ids)\n",
        "\n",
        "# Use the safe decoder after generating outputs\n",
        "output_ids = outputs[0].tolist()\n",
        "decoded_text = safe_decode_with_sentencepiece(output_ids, sp)\n",
        "print(\"Decoded Text:\", decoded_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPLDTSenU6IW",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732655690509,
          "user_tz": 300,
          "elapsed": 174,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "3e233995-bde4-43f6-a12a-f39e9bc3a4f9"
      },
      "id": "bPLDTSenU6IW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded Text: Boston Va Phone number ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇ \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "awdatascience (Nov 26, 2024, 9_37_41 AM).ipynb"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "45499828171143beb531ea7b242eb349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df7acd76e1f14bbda45f9ed524dc1369"
            ],
            "layout": "IPY_MODEL_261d44ba80a441f7bc0208a33cadbc18"
          }
        },
        "08b3b1eaa0214741963b63bfb599ba19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_763622d911184d9da1cbfe389e1541ea",
            "placeholder": "​",
            "style": "IPY_MODEL_46225596a1574405b45aac608b28bde9",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "b2ef4828edfa4384a3839fd5615c8ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_74eb573d6c9b445ba0c71b92e5fe99fa",
            "placeholder": "​",
            "style": "IPY_MODEL_73e8b7676b804d86ace2426b4090f211",
            "value": "bluewall"
          }
        },
        "c1e481170cc247298fdb9afce067bc06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_5f72206ac19a4104b52b03186c3299e5",
            "placeholder": "​",
            "style": "IPY_MODEL_7e34d864fbf648cfa7656c683ff4b592",
            "value": ""
          }
        },
        "024362481ac64922af5f5402e0c1b1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_f86d0b12ba0043da8a239b239b82bbe7",
            "style": "IPY_MODEL_6a799611994e46368831b3dd332001d5",
            "tooltip": ""
          }
        },
        "d1928f54592b4987a64f3430fc584e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d859b7fdcf8e4025a64128be1a53acad",
            "placeholder": "​",
            "style": "IPY_MODEL_4e24a9ba3c1243a9a92b20da81ab41c0",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "261d44ba80a441f7bc0208a33cadbc18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "763622d911184d9da1cbfe389e1541ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46225596a1574405b45aac608b28bde9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74eb573d6c9b445ba0c71b92e5fe99fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73e8b7676b804d86ace2426b4090f211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f72206ac19a4104b52b03186c3299e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e34d864fbf648cfa7656c683ff4b592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f86d0b12ba0043da8a239b239b82bbe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a799611994e46368831b3dd332001d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "d859b7fdcf8e4025a64128be1a53acad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e24a9ba3c1243a9a92b20da81ab41c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46f24f06caf54bfaaedade51484d379c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d76e4b99e07459981390e494181d0a0",
            "placeholder": "​",
            "style": "IPY_MODEL_f764de52d5074cbc8921474e20196185",
            "value": "Connecting..."
          }
        },
        "9d76e4b99e07459981390e494181d0a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f764de52d5074cbc8921474e20196185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df7acd76e1f14bbda45f9ed524dc1369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e44e362df21436190530c0fd5c74988",
            "placeholder": "​",
            "style": "IPY_MODEL_4f5503a771dc4d87b561fa42ffff13be",
            "value": "Kaggle credentials successfully validated."
          }
        },
        "9e44e362df21436190530c0fd5c74988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f5503a771dc4d87b561fa42ffff13be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
